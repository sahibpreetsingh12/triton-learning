# -*- coding: utf-8 -*-
"""practice-5-layer-norm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V5RAaLBZ0iMvksWPWk27dbbKFGhGn9OB
"""

!pip install triton

import torch

a = torch.tensor([5,2,40])

# a = a[None, :]
a = a-3
a = a**2

a

import triton
import torch
import triton.language as tl

"""# My Version -"""

@triton.jit
def layer_normalisation(X_ptr, Y_ptr, M, N, m_stride, n_stride, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(0)

    offsets = tl.arange(0, BLOCK_SIZE)
    mask = offsets < N

    input_ptr = X_ptr + pid*m_stride + offsets*n_stride  # Fixed: removed [:, None] since we want just 1d dimension

    input_var = tl.load(input_ptr, mask=mask, other=0.0)

    row_sum = tl.sum(input_var)
    mean_row = row_sum/N

    var_row_num = (input_var-mean_row)**2
    var_row = tl.sum(var_row_num)/N

    output_num = (input_var - mean_row)/tl.sqrt(var_row + 1e-5)  # Added epsilon

    output_ptr = Y_ptr + offsets * n_stride + pid * m_stride
    tl.store(output_ptr, output_num, mask=mask)  # Fixed typo

"""## Benchmarking against Pytorch"""

import torch
import triton
import triton.language as tl
import time

@triton.jit
def layer_normalisation(X_ptr, Y_ptr, M, N, m_stride, n_stride, BLOCK_SIZE: tl.constexpr):
    pid = tl.program_id(0)

    offsets = tl.arange(0, BLOCK_SIZE)
    mask = offsets < N

    input_ptr = X_ptr + pid*m_stride + offsets*n_stride

    input_var = tl.load(input_ptr, mask=mask, other=0.0)

    row_sum = tl.sum(input_var)
    mean_row = row_sum/N

    var_row_num = (input_var-mean_row) * (input_var-mean_row)  # Changed: use * instead of **2
    var_row = tl.sum(var_row_num)/N

    output_num = (input_var - mean_row)/tl.sqrt(var_row + 1e-5)

    output_ptr = Y_ptr + offsets * n_stride + pid * m_stride
    tl.store(output_ptr, output_num, mask=mask)


def triton_layer_norm(X: torch.Tensor) -> torch.Tensor:
    """Apply layer normalization to each row"""
    assert X.dim() == 2, "Input must be 2D"
    assert X.is_cuda, "Input must be on CUDA"
    assert X.is_contiguous(), "Input must be contiguous"

    M, N = X.shape
    Y = torch.empty_like(X)

    # Find next power of 2 for BLOCK_SIZE
    BLOCK_SIZE = 1
    while BLOCK_SIZE < N:
        BLOCK_SIZE *= 2

    grid = (M,)  # One program per row

    layer_normalisation[grid](
        X, Y, M, N,
        X.stride(0), X.stride(1),
        BLOCK_SIZE
    )

    return Y


# Test correctness
def test_layer_norm():
    print("Testing Layer Normalization")
    print("=" * 40)

    # Test case: 3x3 matrix
    X = torch.tensor([[1.0, 2.0, 3.0],
                      [4.0, 5.0, 6.0],
                      [7.0, 8.0, 9.0]], device='cuda')

    print("Input (3x3):")
    print(X)

    # Our Triton version
    Y_triton = triton_layer_norm(X)

    # PyTorch reference (LayerNorm expects last dimension to normalize)
    layer_norm = torch.nn.LayerNorm(X.shape[1], eps=1e-5).cuda()
    Y_torch = layer_norm(X)

    print("\nTriton result:")
    print(Y_triton)

    print("\nPyTorch reference:")
    print(Y_torch)

    print(f"\nResults match: {torch.allclose(Y_triton, Y_torch, rtol=1e-4, atol=1e-4)}")

    # Check normalization properties
    print("\nNormalization check (each row should have mean≈0, std≈1):")
    means = Y_triton.mean(dim=1)
    stds = Y_triton.std(dim=1)
    print(f"Row means: {means}")
    print(f"Row stds: {stds}")


# Performance benchmark
def benchmark_layer_norm():
    print("\n" + "=" * 50)
    print("PERFORMANCE BENCHMARK")
    print("=" * 50)

    # Test different matrix sizes
    sizes = [(128, 512), (512, 1024), (1024, 2048)]

    for M, N in sizes:
        print(f"\nTesting {M}×{N} matrix:")

        X = torch.randn(M, N, device='cuda')

        # Triton timing
        torch.cuda.synchronize()
        start = time.time()
        for _ in range(100):
            Y_triton = triton_layer_norm(X)
        torch.cuda.synchronize()
        triton_time = (time.time() - start) / 100

        # PyTorch timing
        layer_norm = torch.nn.LayerNorm(N, eps=1e-5).cuda()
        torch.cuda.synchronize()
        start = time.time()
        for _ in range(100):
            Y_torch = layer_norm(X)
        torch.cuda.synchronize()
        pytorch_time = (time.time() - start) / 100

        # Compare
        speedup = pytorch_time / triton_time
        print(f"  Triton:  {triton_time*1000:.3f} ms")
        print(f"  PyTorch: {pytorch_time*1000:.3f} ms")
        print(f"  Speedup: {speedup:.2f}x {'(Triton faster)' if speedup > 1 else '(PyTorch faster)'}")

        # Verify correctness
        match = torch.allclose(Y_triton, Y_torch, rtol=1e-4, atol=1e-4)
        print(f"  Correct: {match}")


if __name__ == "__main__":
    test_layer_norm()
    benchmark_layer_norm()

"""## Optimised"""

import torch
import triton
import triton.language as tl
import time

@triton.jit
def optimized_layer_norm(X_ptr, Y_ptr, M, N, x_row_stride, BLOCK_SIZE_N: tl.constexpr):
    # Each program processes multiple rows
    row_idx = tl.program_id(0)

    # Process one row at a time, but with better memory access
    col_offsets = tl.arange(0, BLOCK_SIZE_N)
    mask = col_offsets < N

    # Load entire row at once
    x_ptrs = X_ptr + row_idx * x_row_stride + col_offsets
    x = tl.load(x_ptrs, mask=mask, other=0.0)

    # Compute mean
    x_sum = tl.sum(x, axis=0)
    x_mean = x_sum / N

    # Compute variance
    x_centered = x - x_mean
    x_var = tl.sum(x_centered * x_centered, axis=0) / N

    # Normalize
    x_normalized = x_centered / tl.sqrt(x_var + 1e-5)

    # Store result
    y_ptrs = Y_ptr + row_idx * x_row_stride + col_offsets
    tl.store(y_ptrs, x_normalized, mask=mask)


@triton.jit
def vectorized_layer_norm(X_ptr, Y_ptr, M, N, x_row_stride,
                         BLOCK_SIZE_M: tl.constexpr, BLOCK_SIZE_N: tl.constexpr):
    """Process multiple rows per program for better GPU utilization"""

    # Each program handles a block of rows
    pid_m = tl.program_id(0)

    # Calculate which rows this program handles
    row_start = pid_m * BLOCK_SIZE_M

    # Column offsets (all columns for each row)
    col_offsets = tl.arange(0, BLOCK_SIZE_N)
    col_mask = col_offsets < N

    # Process each row in this block - use range with BLOCK_SIZE_M (compile-time constant)
    for i in range(BLOCK_SIZE_M):
        row_idx = row_start + i

        # Use conditional instead of break (Triton doesn't support break)
        if row_idx < M:
            # Load one row
            x_ptrs = X_ptr + row_idx * x_row_stride + col_offsets
            x = tl.load(x_ptrs, mask=col_mask, other=0.0)

            # Compute statistics for this row
            x_sum = tl.sum(x)
            x_mean = x_sum / N

            x_centered = x - x_mean
            x_var = tl.sum(x_centered * x_centered) / N

            # Normalize
            x_normalized = x_centered / tl.sqrt(x_var + 1e-5)

            # Store
            y_ptrs = Y_ptr + row_idx * x_row_stride + col_offsets
            tl.store(y_ptrs, x_normalized, mask=col_mask)


def triton_layer_norm_optimized(X: torch.Tensor) -> torch.Tensor:
    """Optimized layer normalization - one program per row"""
    assert X.dim() == 2, "Input must be 2D"
    assert X.is_cuda, "Input must be on CUDA"
    assert X.is_contiguous(), "Input must be contiguous"

    M, N = X.shape
    Y = torch.empty_like(X)

    # Power of 2 for columns
    BLOCK_SIZE_N = 1
    while BLOCK_SIZE_N < N:
        BLOCK_SIZE_N *= 2

    # Launch one program per row (this is actually optimal for layer norm)
    grid = (M,)

    optimized_layer_norm[grid](
        X, Y, M, N,
        X.stride(0),
        BLOCK_SIZE_N
    )

    return Y


def triton_layer_norm_vectorized(X: torch.Tensor) -> torch.Tensor:
    """Vectorized version - fewer programs, each handling multiple rows"""
    assert X.dim() == 2, "Input must be 2D"
    assert X.is_cuda, "Input must be on CUDA"
    assert X.is_contiguous(), "Input must be contiguous"

    M, N = X.shape
    Y = torch.empty_like(X)

    # Block sizes
    BLOCK_SIZE_M = 4  # Each program handles 4 rows
    BLOCK_SIZE_N = 1
    while BLOCK_SIZE_N < N:
        BLOCK_SIZE_N *= 2

    # Grid size
    grid_m = triton.cdiv(M, BLOCK_SIZE_M)
    grid = (grid_m,)

    vectorized_layer_norm[grid](
        X, Y, M, N,
        X.stride(0),
        BLOCK_SIZE_M, BLOCK_SIZE_N
    )

    return Y


# Test both versions
def test_optimized_versions():
    print("Testing Optimized Layer Normalization")
    print("=" * 50)

    # Test case
    X = torch.randn(8, 16, device='cuda')

    # Optimized versions
    Y_opt1 = triton_layer_norm_optimized(X)
    Y_opt2 = triton_layer_norm_vectorized(X)

    # PyTorch reference
    layer_norm = torch.nn.LayerNorm(X.shape[1], eps=1e-5).cuda()
    Y_torch = layer_norm(X)

    print(f"Optimized1 vs PyTorch: {torch.allclose(Y_opt1, Y_torch, rtol=1e-4)}")
    print(f"Optimized2 vs PyTorch: {torch.allclose(Y_opt2, Y_torch, rtol=1e-4)}")

    print("\nSample values:")
    print("PyTorch result (first row):", Y_torch[0, :8])
    print("Optimized1 (first row):   ", Y_opt1[0, :8])
    print("Optimized2 (first row):   ", Y_opt2[0, :8])


def benchmark_all_versions():
    print("\n" + "=" * 60)
    print("PERFORMANCE COMPARISON")
    print("=" * 60)

    sizes = [(128, 512), (512, 1024), (1024, 2048)]

    for M, N in sizes:
        print(f"\nTesting {M}×{N} matrix:")
        X = torch.randn(M, N, device='cuda')

        # Warm up
        for _ in range(10):
            _ = triton_layer_norm_optimized(X)

        # Time optimized version
        torch.cuda.synchronize()
        start = time.time()
        for _ in range(100):
            Y_opt = triton_layer_norm_optimized(X)
        torch.cuda.synchronize()
        triton_opt_time = (time.time() - start) / 100

        # Time PyTorch
        layer_norm = torch.nn.LayerNorm(N, eps=1e-5).cuda()
        torch.cuda.synchronize()
        start = time.time()
        for _ in range(100):
            Y_torch = layer_norm(X)
        torch.cuda.synchronize()
        pytorch_time = (time.time() - start) / 100

        speedup = pytorch_time / triton_opt_time
        print(f"  Triton Optimized: {triton_opt_time*1000:.3f} ms")
        print(f"  PyTorch:          {pytorch_time*1000:.3f} ms")
        print(f"  Speedup:          {speedup:.2f}x")

        # Verify correctness
        match = torch.allclose(Y_opt, Y_torch, rtol=1e-4, atol=1e-4)
        print(f"  Correct: {match}")


if __name__ == "__main__":
    test_optimized_versions()
    benchmark_all_versions()

"""### As we slowly moved from 0.62x --> 1.48x but what if we moved the same code and took into account GPU warmup"""

import torch
import triton
import triton.language as tl
import time

@triton.jit
def optimized_layer_norm(X_ptr, Y_ptr, M, N, x_row_stride, BLOCK_SIZE_N: tl.constexpr):
    row_idx = tl.program_id(0)
    col_offsets = tl.arange(0, BLOCK_SIZE_N)
    mask = col_offsets < N

    x_ptrs = X_ptr + row_idx * x_row_stride + col_offsets
    x = tl.load(x_ptrs, mask=mask, other=0.0)

    x_sum = tl.sum(x, axis=0)
    x_mean = x_sum / N

    x_centered = x - x_mean
    x_var = tl.sum(x_centered * x_centered, axis=0) / N

    x_normalized = x_centered / tl.sqrt(x_var + 1e-5)

    y_ptrs = Y_ptr + row_idx * x_row_stride + col_offsets
    tl.store(y_ptrs, x_normalized, mask=mask)


def triton_layer_norm_optimized(X: torch.Tensor) -> torch.Tensor:
    assert X.dim() == 2, "Input must be 2D"
    assert X.is_cuda, "Input must be on CUDA"
    assert X.is_contiguous(), "Input must be contiguous"

    M, N = X.shape
    Y = torch.empty_like(X)

    BLOCK_SIZE_N = 1
    while BLOCK_SIZE_N < N:
        BLOCK_SIZE_N *= 2

    grid = (M,)

    optimized_layer_norm[grid](
        X, Y, M, N,
        X.stride(0),
        BLOCK_SIZE_N
    )

    return Y


def proper_benchmark():
    """Proper GPU benchmarking with adequate warmup"""
    print("PROPER GPU BENCHMARKING WITH WARMUP")
    print("=" * 60)

    sizes = [(128, 512), (512, 1024), (1024, 2048), (2048, 4096)]

    for M, N in sizes:
        print(f"\n🔥 Testing {M}×{N} matrix:")
        print("-" * 30)

        # Create test data
        X = torch.randn(M, N, device='cuda', dtype=torch.float32)

        # Initialize PyTorch layer norm
        layer_norm = torch.nn.LayerNorm(N, eps=1e-5, device='cuda', dtype=torch.float32)

        print("📋 Phase 1: Compilation & Warmup")

        # EXTENSIVE WARMUP - Critical for fair comparison!
        print("  • Triton compilation...")
        _ = triton_layer_norm_optimized(X)  # First call triggers compilation

        print("  • Triton warmup...")
        for _ in range(50):  # Much more warmup
            _ = triton_layer_norm_optimized(X)

        print("  • PyTorch warmup...")
        for _ in range(50):  # Same for PyTorch
            _ = layer_norm(X)

        # Clear any pending operations
        torch.cuda.synchronize()

        print("📊 Phase 2: Timing (200 iterations each)")

        # Time Triton with proper synchronization
        torch.cuda.synchronize()
        triton_times = []
        for _ in range(200):
            start = time.perf_counter()
            Y_triton = triton_layer_norm_optimized(X)
            torch.cuda.synchronize()  # Wait for completion
            end = time.perf_counter()
            triton_times.append(end - start)

        # Time PyTorch
        torch.cuda.synchronize()
        pytorch_times = []
        for _ in range(200):
            start = time.perf_counter()
            Y_torch = layer_norm(X)
            torch.cuda.synchronize()
            end = time.perf_counter()
            pytorch_times.append(end - start)

        # Statistical analysis
        triton_times = torch.tensor(triton_times)
        pytorch_times = torch.tensor(pytorch_times)

        # Remove outliers (top/bottom 5%)
        triton_times = triton_times.sort()[0][10:-10]  # Remove 10 highest/lowest
        pytorch_times = pytorch_times.sort()[0][10:-10]

        triton_mean = triton_times.mean().item()
        triton_std = triton_times.std().item()
        pytorch_mean = pytorch_times.mean().item()
        pytorch_std = pytorch_times.std().item()

        speedup = pytorch_mean / triton_mean

        print(f"📈 Results:")
        print(f"  Triton:   {triton_mean*1000:.3f} ± {triton_std*1000:.3f} ms")
        print(f"  PyTorch:  {pytorch_mean*1000:.3f} ± {pytorch_std*1000:.3f} ms")
        print(f"  Speedup:  {speedup:.3f}x {'🚀' if speedup > 1 else '🐌'}")

        # Verify correctness
        correctness = torch.allclose(Y_triton, Y_torch, rtol=1e-4, atol=1e-4)
        print(f"  Correct:  {correctness} {'✅' if correctness else '❌'}")

        # Memory bandwidth analysis
        bytes_per_element = 4  # float32
        total_bytes = M * N * 2 * bytes_per_element  # Read + Write

        triton_bandwidth = (total_bytes / triton_mean) / 1e9  # GB/s
        pytorch_bandwidth = (total_bytes / pytorch_mean) / 1e9

        print(f"  Bandwidth - Triton: {triton_bandwidth:.1f} GB/s, PyTorch: {pytorch_bandwidth:.1f} GB/s")


def quick_warmup_comparison():
    """Compare with/without proper warmup to show the difference"""
    print("\n" + "=" * 60)
    print("WARMUP IMPACT DEMONSTRATION")
    print("=" * 60)

    X = torch.randn(1024, 2048, device='cuda')
    layer_norm = torch.nn.LayerNorm(2048, eps=1e-5, device='cuda')

    print("\n🥶 WITHOUT WARMUP (includes compilation + cold start):")

    # Time first run (cold)
    torch.cuda.synchronize()
    start = time.perf_counter()
    Y1 = triton_layer_norm_optimized(X)
    torch.cuda.synchronize()
    cold_time = time.perf_counter() - start

    # Time PyTorch first run
    torch.cuda.synchronize()
    start = time.perf_counter()
    Y2 = layer_norm(X)
    torch.cuda.synchronize()
    pytorch_cold = time.perf_counter() - start

    print(f"Triton (cold):   {cold_time*1000:.3f} ms")
    print(f"PyTorch (cold):  {pytorch_cold*1000:.3f} ms")
    print(f"Speedup (cold):  {pytorch_cold/cold_time:.3f}x")

    print("\n🔥 WITH WARMUP (steady state performance):")

    # Warmup
    for _ in range(50):
        _ = triton_layer_norm_optimized(X)
        _ = layer_norm(X)

    # Time warm runs
    torch.cuda.synchronize()
    start = time.perf_counter()
    for _ in range(100):
        Y1 = triton_layer_norm_optimized(X)
    torch.cuda.synchronize()
    warm_time = (time.perf_counter() - start) / 100

    torch.cuda.synchronize()
    start = time.perf_counter()
    for _ in range(100):
        Y2 = layer_norm(X)
    torch.cuda.synchronize()
    pytorch_warm = (time.perf_counter() - start) / 100

    print(f"Triton (warm):   {warm_time*1000:.3f} ms")
    print(f"PyTorch (warm):  {pytorch_warm*1000:.3f} ms")
    print(f"Speedup (warm):  {pytorch_warm/warm_time:.3f}x")

    print(f"\n💡 Improvement from warmup:")
    print(f"Triton got {cold_time/warm_time:.2f}x faster")
    print(f"PyTorch got {pytorch_cold/pytorch_warm:.2f}x faster")


if __name__ == "__main__":
    proper_benchmark()
    quick_warmup_comparison()

